%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Short Sectioned Assignment
% LaTeX Template
% Version 1.0 (5/5/12)
%
% This template has been downloaded from:
% http://www.LaTeXTemplates.com
%
% Original author:
% Frits Wenneker (http://www.howtotex.com)
%
% License:
% CC BY-NC-SA 3.0 (http://creativecommons.org/licenses/by-nc-sa/3.0/)
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%----------------------------------------------------------------------------------------
%	PACKAGES AND OTHER DOCUMENT CONFIGURATIONS
%----------------------------------------------------------------------------------------

\documentclass[paper=a4, fontsize=11pt]{scrartcl} % A4 paper and 11pt font size

\usepackage[T1]{fontenc} % Use 8-bit encoding that has 256 glyphs
%\usepackage{fourier} % Use the Adobe Utopia font for the document - comment this line to return to the LaTeX default
\usepackage[english]{babel} % English language/hyphenation
\usepackage{amsmath,amsfonts,amsthm} % Math packages

\usepackage{pdflscape}


\usepackage{graphicx} % figures
\usepackage{subcaption} % captions for figures
\usepackage{lipsum} % Used for inserting dummy 'Lorem ipsum' text into the template
\usepackage[margin=0.25in]{geometry}
\usepackage{sectsty} % Allows customizing section commands
\usepackage{rotating} % for long tables
\allsectionsfont{\centering \normalfont\scshape} % Make all sections centered, the default font and small caps

\usepackage{fancyhdr} % Custom headers and footers
\pagestyle{fancyplain} % Makes all pages in the document conform to the custom headers and footers
\fancyhead{} % No page header - if you want one, create it in the same way as the footers below
\fancyfoot[L]{} % Empty left footer
\fancyfoot[C]{} % Empty center footer
\fancyfoot[R]{\thepage} % Page numbering for right footer
\renewcommand{\headrulewidth}{0pt} % Remove header underlines
\renewcommand{\footrulewidth}{0pt} % Remove footer underlines
\setlength{\headheight}{13.6pt} % Customize the height of the header
\usepackage{tabularx,ragged2e,booktabs,caption} % tabular tables
\numberwithin{equation}{section} % Number equations within sections (i.e. 1.1, 1.2, 2.1, 2.2 instead of 1, 2, 3, 4)
\numberwithin{figure}{section} % Number figures within sections (i.e. 1.1, 1.2, 2.1, 2.2 instead of 1, 2, 3, 4)
\numberwithin{table}{section} % Number tables within sections (i.e. 1.1, 1.2, 2.1, 2.2 instead of 1, 2, 3, 4)

\setlength\parindent{0pt} % Removes all indentation from paragraphs - comment this line for an assignment with lots of text

%----------------------------------------------------------------------------------------
%	TITLE SECTION
%----------------------------------------------------------------------------------------

\newcommand{\horrule}[1]{\rule{\linewidth}{#1}} % Create horizontal rule command with 1 argument of height

\title{	
\normalfont \normalsize 
\textsc{Central Washington University, Department of Computer Science} \\ [25pt] % Your university, school and/or department name(s)
\horrule{0.5pt} \\[0.4cm] % Thin top horizontal rule
\huge CS471 Project 4 \\ % The assignment title
\horrule{2pt} \\[0.5cm] % Thick bottom horizontal rule
}

\author{Nick Rohde} % Your name

\date{\normalsize 22$^{nd}$ May, 2018} % Today's date or a custom date

\usepackage{hyperref}
\hypersetup
{
	colorlinks=true,
	citecolor=black,
	filecolor=black,
	linkcolor=black,
	urlcolor=blue,
	linktoc=all,
	linkcolor=blue,
}


\begin{document}

\maketitle % Print the title

%----------------------------------------------------------------------------------------
%	PROBLEM 1
%----------------------------------------------------------------------------------------

\section{Introduction}\label{S1}
	For this project, we implemented Particle Swarm Optimization (PSO) and the Firefly Algorithm (FFA). Both PSO and FFA are swarm intelligence algorithms that attempt to mimic the swarm behavior of simple organisms (s.a. ants or fireflies) to find the global optimum of a given fitness function. In this case, we continued to use the fifteen cost functions from Project 1 as fitness functions. \\
	
	\subsection{Particle Swarm Overview}\label{S11}
		The implementation of PSO consists of two main components, (1) velocity calculation and (2) particle movement. The first step determined how much a given particle would move, and the second step would then move the particle to it's new location. At all times, the particles would move towards the current best particle. This was updated on-the-fly, so if a particle moved to a location in the search space that was better than the global best it was moving towards, the swarm then would move towards it. For this algorithm, we used three main tuning parameters: the weight ($\omega$) used to adjust the velocity of a particle; and two scaling factors which determined whether the particles should favor the local (C$_1$) or global (C$_2$) best solution. The values of these three variables can be found in the \hyperref[T21]{table of parameters}.
		
	
	\subsection{Firefly Algorithm Overview}\label{S12}
		The Firefly Algorithm works much like PSO. Once again, we have a population of particles which all move towards the best solution, however, this time particles do not move towards the best solution regardless, they will only move towards the best particle within their local region. This is controlled by the Intensity and Attractiveness. Unlike the PSO, the entire swarm was updated at once, and changes were applied to the population once all particles had already moved. This algorithm used four tuning parameters, namely: two scaling factors Alpha ($\alpha$) and Gamma ($\gamma$), the attractiveness when two fireflies are next to each other Beta$_0$ ($\beta_0$), and the light Intensity when two particles are next to each other Intensity$_0$ ($I_0$). The final values of these four parameters can be found in the \hyperref[T21]{table of parameters}.
			
			
\section{Experimentation}\label{S2}
	The experimentation for both PSO and FFA were done using the parameters that can be found in the \hyperref[T21]{table of parameters}. For the most part, only small changes were made to the parameters (as discussed in \hyperref[S21]{Section 2.1}) and the original values or value ranges were used for the most part.
	
	\begin{minipage}{\linewidth}
		\centering
		\captionof{table}{Table of Parameters}
		\begin{tabular}{cc|cc}\label{T21}
			Parameter       			& Acronym 		& PSO 		& FFA  		\\
			\hline
			Dimensions					& (D)			& 10/20/30	& 10/20/30	\\
			Iterations					& (Itr)			& 500		& 100  		\\
			Population Size				& (P)			& 200		& 100  		\\
			Constant 1					& (C$_1$)		& 0.8		& *    		\\
			Constant 2					& (C$_2$)		& 1.2		& *			\\
			Weight						& ($\omega$)	& 0.6		& *			\\
			Alpha						& ($\alpha$)	& *			& 0.8		\\
			Beta$_0$					& ($\beta_0$)	& *			& 0.4		\\
			Gamma						& ($\gamma$)	& *			& 1.0		\\
			Intensity$_0$ 				& ($I_0$)		& *			& 1.0		\\
		\end{tabular}
		\bigskip\\
		\small{* denotes the parameter was not used by that algorithm}
	\end{minipage}
	
	\subsection{Changes to Parameters}\label{S21}
	 The parameters that were changed for PSO were the number of Iterations (Itr), the Population Size (P), and the Weight Constant ($\omega$). For FFA, the parameters that were changed are !!TODO!!\\
	 
	 The changes made to PSO parameters were made for two reasons, firstly, Itr and P were increased simply because the algorithm does not have a very long execution time, thus, making these large increases from 100 to 500 and 50 to 200, respectively, were feasible without changing the execution time too much. The impact of this was an increase of computation time of about 20 times (from approximately 30 seconds to 600 seconds), which, interestingly, is exactly the scaling that was applied to the two parameters, suggesting this algorithm scales linearly on these parameters. \\
	 Secondly, the $\omega$ component was changed because it was determined experimentally that the original value, 0.9, was not the best value. The functions all reacted differently to changes to the parameters, however, with the original values of C$_1$ and C$_2$ and $\omega$ set to 0.6, the majority of the functions did better than with original settings. One of the main reasons why this value was chosen was that $f_5$ (Griewangk's Function) was minimized using these parameters, that is in 10, 20, and 30 dimensions the global optimum of $f_5(x) = 0$ was found, something that did not occur with any of the previous algorithms or different values of $\omega$.
	 	 
	
\section{Analysis} \label{S3}
	Now, we will discuss the data displayed in \hyperref[S4]{Section 4}. In the discussion below we will reference some of the parameters from the \hyperref[T21]{table of parameters} by the acronyms provided in column 2. Test settings can be found in \hyperref[T41]{Table 4.1} \\
	
	\subsection{Execution Time} \label{S31}
		For these two algorithms, PSO and FFA, we can immediately see in the graphs provided in \hyperref[S4]{Section 4} that PSO beats FFA by a long shot in execution time, even though PSO is actually running more iterations with a larger population than FFA. So, in this case there is a very clear winner. When we compare PSO to some of the algorithms from the previous project, we can see that PSO is not as fast as the Genetic Algorithm (GE), and slightly slower than the three Differential Evolution (DE) strategies we looked at. Overall, we can say that, for the quality of solutions that PSO provides (discussed in \hyperref[S32]{Section 3.2}), it definitely is worth the small investment in time compared to the GE and DE.
		
	
	\subsection{Quality of Solutions} \label{S32}
		Now, let us look at the quality of solutions. Once again, we can see that PSO pulls ahead of FFA. One very interesting part is that PSO actually managed to locate the global optimum of Griewangk's function ($f_5$) as can be seen in \hyperref[F_Best10]{Figure 1}, \hyperref[F_Best20]{Figure 2}, and \hyperref[F_Best30]{Figure 3} which show the best values found by FFA and PSO as well as the Genetic Algorithm (GE) and DE/best/1/exp (DE) from the previous project. This is something that did not occur with any of the algorithms so far, PSO was the only algorithm that found any of the global minima of all functions. Though the optimal point ($x* = 0,0, ..., 0$) is fairly trivial, the function itself is not, thus, finding this point is very impressive, and certainly unexpected. So, we can say that PSO is at least the best strategy for this function. Furthermore, PSO was also able to provide higher quality results for most of the other functions in the same amount of time. It should be said that the implementation of FFA was not the best possible implementation, so this could have had an impact on this. The FFA was able to beat the results of PSO in functions $f_2$, $f_7$, and $f_8$, though these were only by a small margin, and still not anywhere close to the global optimum. When we compare these results to those of the GE or DE, we can see that they were able to keep up with the FFA, and generally provided better solutions. Similarly, PSO only did marginally better or worse than the GE or DE, so here we can say that these four strategies are well matched, with each strategy consistently doing better than the others in a subset of the functions. 
		
		
	\subsection{Conclusions} \label{S33}
		Overall, 
	 

	
\section{Data} \label{S4}
	All data displayed in this section was generated on a windows machine with a 3.2GHz AMD Ryzen 7 1700X processor, and 16 GB RAM. \hyperref[T41]{Table 4.1} below shows the settings that were used for the tests; for GA and DE, all settings from \hyperref[T21]{table 2.1} were used to configure the algorithms. The data was written to files after all tests for a function were completed.\\ Note, the values of $f_3$ were omitted in Figures 1-3 as they were magnitudes larger than the other functions, thus resulting in a skewed graph. The results for this function are displayed in Figure 4.

	\begin{minipage}{\linewidth}
		\centering
		\captionof{table}{Test Settings}
		\begin{tabular}{c|cccc}\label{T41}
			Parameter       			& GA 		& DE   	& PSO	& FFA	\\
			\hline
			\# of Tests per Function	& 100		& 100	& 96	& 96	\\
			Generations/Iterations		& 100		& 100	& 500	& 100	\\
			\# of Threads				& 16		& 16	& 16	& 16	\\
		\end{tabular}
		\bigskip\\
	\end{minipage}

\begin{figure}[!ht]
	\includegraphics[width=\linewidth]{Best_Comparison_10D.png}
	\caption{Best Value of different Strategies in 10 dimensions. ($f_3$ omitted)}
	\label{F_Best10}
\end{figure}
\begin{figure}[!ht]
	\includegraphics[width=\linewidth]{Best_Comparison_20D.png}
	\caption{Best Value of different Strategies in 10 dimensions. ($f_3$ omitted)}
	\label{F_Best20}
\end{figure}
\begin{figure}[!ht]
	\includegraphics[width=\linewidth]{Best_Comparison_30D.png}
	\caption{Best Value of different Strategies in 10 dimensions. ($f_3$ omitted)}
	\label{F_Best30}
\end{figure}
\begin{figure}[!ht]
	\includegraphics[width=\linewidth]{Best_Comparison_F3.png}
	\caption{Best Value of different Strategies for $f_3$ in 10, 20, and 30 dimensions.}
	\label{F_Best3}
\end{figure}


%----------------------------------------------------------------------------------------
% DE
\pagebreak

\begin{landscape}
	\begin{table}
		\tiny
		\centering
		\caption{Computation comparison for PSO, FFA, GA, and DE/best/1/exp in 10 dimensions}
		\label{Tab1d}
		\begin{tabular}{c|ccccc|ccccc|ccccc|ccccc}
			\noalign{\smallskip}\hline\noalign{\smallskip}
			Problem & \multicolumn{5}{c}{PSO}& \multicolumn{5}{|c|}{FFA} &  \multicolumn{5}{c}{GA} & \multicolumn{5}{|c}{Differential Evolution (best/1/exp)}\\ 
			\noalign{\smallskip}\hline\noalign{\smallskip}
			& Avg & Median & Range & SD & T(s) & Avg & Median
			& Range & SD & T(s) & Avg & Median & Range & SD &
			T(s) & Avg & Median & Range & SD &
			T(s)\\ 
			\noalign{\smallskip}\hline\noalign{\smallskip}
			$f_{1}$ & -2622.20 & -2584.02 & 772.22 & 169.738 & 1.22166 & -976.863 & -1012.25 & 3865.02 & 618.825 & inf & -4176.13 & -4178.55 & 36.84 & 8.82272 & 0.08685 & -3832.41 & -3890.96 & 1059.51 & 240.894 & 0.10871\\
			$f_{2}$ & 2834.90 & 2980.17 & 4216.87 & 734.686 & 1.25118 & 19553.1 & 22817.8 & 47058.2 & 12466.9 & inf & 5.72411 & 4.91465 & 27.8500 & 4.00083 & 0.08033 & 0.00475 & 0.00415 & 0.01435 & 0.00281 & 0.08292\\
			$f_{3}$ & $1\times10^{8}$ & $1\times10^{8}$ & $2\times10^{8}$ & $5\times10^{7}$ & 1.2525 & $8\times10^{9}$ & $8\times10^{9}$ & $2\times10^{10}$ & $7\times10^{10}$ & inf & 3289.79 & 2300.89 & 19541.9 & 3360.49 & 0.09204 & 73.1204 & 28.3278 & 1028.60 & 126.416 & 0.09707\\
			$f_{4}$ & -1660.63 & -1659.73 & 362.64 & 67.7852 & 1.28748 & -972.742 & -1028.11 & 3050.51 & 605.209 & inf & -1987.59 & -1987.87 & 17.41 & 4.00164 & 0.09262 & -1970.10 & -1969.97 & 21.68 & 4.86361 & 0.13077\\
			$f_{5}$ & 0.0 & 0.0 & 0.0 & 0.0 & 0.87154 & 165.358 & 188.306 & 352.808 & 89.8823 & inf & 0.93584 & 1.0158 & 0.60774 & 0.15318 & 0.09403 & 0.68853 & 0.68734 & 0.64512 & 0.11295 & 0.12736\\
			$f_{6}$ & -10.6338 & -10.5579 & 1.001 & 0.21358 & 0.87445 & -9.59784 & -9.62849 & 3.80683 & 0.83945 & inf & -13.1038 & -13.1372 & 0.9009 & 0.19049 & 0.09269 & -11.9926 & -11.9884 & 1.2744 & 0.21064 & 0.17124\\
			$f_{7}$ & 31.1721 & 31.5065 & 12.3355 & 2.37445 & 1.39218 & 37.4517 & 37.8158 & 33.5525 & 7.14586 & inf & 6.23605 & 6.22802 & 6.05244 & 1.39085 & 0.09567 & 3.14954 & 3.08748 & 2.892 & 0.58377 & 0.10150\\
			$f_{8}$ & 45.5095 & 46.3197 & 37.0175 & 7.12484 & 1.3130 & 83.5553 & 80.4102 & 155.910 & 34.5119 & inf & -25.0689 & -25.1541 & 6.4113 & 1.32092 & 0.10064 & -20.7944 & -21.1628 & 11.4993 & 2.58177 & 0.11278\\
			$f_{9}$ & 106.600 & 107.328 & 27.9954 & 5.54897 & 1.45141 & 140.517 & 142.608 & 95.0674 & 23.4167 & inf & 10.3034 & 10.1336 & 17.4389 & 3.96686 & 0.09162 & 0.33048 & 0.30682 & 0.58891 & 0.11243 & 0.09062\\
			$f_{10}$ & -4180.18 & -4155.4 & 1354.2 & 286.645& 1.37728 & -1450.32 & -1327.52 & 4352.35 & 684.081 & inf & -6602.60 & -6523.94 & 2639.06 & 516.291 & 0.09539 & -4211.73 & -4212.55 & 1995.98 & 350.215 & 0.20236\\
			$f_{11}$ & -2447.15 & -2426.06 & 714.54 & 151.367 & 1.24668 & -1574.70 & -1587.96 & 1753.38 & 358.979 & inf & -3767.89 & -3760.42 & 549.12 & 125.620 & 0.08889 & -2442.54 & -2436.43 & 860.21 & 182.351 & 0.20240\\
			$f_{12}$ & 0.37966 & 0.42076 & 0.69211 & 0.14737 & 0.89521 & 3.79808 & 3.94242 & 2.19476 & 0.35337 & inf & 1.20919 & 1.18109 & 1.70555 & 0.29672 & 0.09350 & 2.67576 & 2.68145 & 0.76149 & 0.166323 & 0.19861\\
			$f_{13}$ & -5.31691 & -5.24234 & 1.74729 & 0.34319 & 1.2663 & -4.27304 & -4.24829 & 2.34485 & 0.42335 & inf & -9.34599 & -9.35668& 0.68065 & 0.14200 & 0.09629 & -7.65443 & -7.65045 & 1.91915 & 0.40761 & 0.13025\\
			$f_{14}$ & -3.46675& -3.28799 & 3.32706 & 0.63961 & 0.91806 & -0.6788 & -0.7163 & 2.22288 & 0.48339 & inf & -6.60200 & -6.49318 & 3.27495 & 0.48602 & 0.09370 & -3.50882 & -3.51655 & 1.79211 & 0.40070 & 0.15582\\
			$f_{15}$ & -0.19735& -0.19211 & 0.18674 & 0.03452 & 1.02412 & -0.12680 & -0.12630 & 0.06660 & 0.01054 & inf & -2.78525 & -1.55306 & 8.74724 & 2.77551 & 0.08897 & -2.82619 & -1.57213 & 9.21059 & 3.051163 & 0.072929\\		
			
			\noalign{\smallskip}\hline\noalign{\smallskip}
			Mean & 7723760 & 8333854 & $1\times10^{7}$ & 3694796 & 1.17620 & $5\times10^{8}$ & $5\times10^{8}$ & $1\times10^{9}$ & $4\times10^{8}$ & inf & -885.128 & -945.474 & 1523.86 & 268.663 & 0.09222 & -828.240 & -834.714 & 333.105 & 60.8247 & 0.13236 \\
			\noalign{\smallskip}\hline\noalign{\smallskip}
			\multicolumn{16}{l}{\tiny $^1$ 3.2GHz AMD Ryzen 7 1700X, 16 GB RAM}
		\end{tabular}\label{DE_30}
	\end{table}


% DE
%----------------------------------------------------------------------------------------
% DE1

	\begin{table}
		\tiny
		\centering
		\caption{Computation comparison for PSO, FFA, GA, and DE/best/1/exp in 20 dimensions}
		\label{Tab1d}
		\begin{tabular}{c|ccccc|ccccc|ccccc|ccccc}
		\noalign{\smallskip}\hline\noalign{\smallskip}
		Problem & \multicolumn{5}{c}{PSO}& \multicolumn{5}{|c|}{FFA} &  \multicolumn{5}{c}{GA} & \multicolumn{5}{|c}{Differential Evolution (best/1/exp)}\\ 
		\noalign{\smallskip}\hline\noalign{\smallskip}
			 & Avg & Median & Range & SD & T(s) & Avg & Median
	                 & Range & SD & T(s) & Avg & Median & Range & SD &
	                 T(s) & Avg & Median & Range & SD &
	                 T(s)\\ 
	\noalign{\smallskip}\hline\noalign{\smallskip}
	 			$f_{1}$ & -3781.78 & -3727.01 & 1247.9 & 236.336 & 2.47286 & -1628.66 & -1741.27 & 3978.21 & 779.325 & inf & -7700.43 & -7715.74 & 743.37 & 167.837 & 0.11335 & -4066.83 & -4044.23 & 1403.78 & 301.023 & 0.24644\\
	 			$f_{2}$ & 16587.9 & 16909.2 & 8126.7 & 1681.55 & 2.48806 & 42048.6 & 52025 & 81651.7 & 25584.6 & inf & 391.940 & 363.375 & 766.085 & 143.778 & 0.1099 & 9.21348 & 8.15146 & 30.1959 & 5.17659 & 0.11699\\
	 			$f_{3}$ & $2\times10^9$ & $2\times10^9$ & $3\times10^9$ & $7\times10^8$ & 2.49684 & $1\times10^{10}$ & $1\times10^{10}$ & $4\times10^{10}$ & $1\times10^{10}$ & inf & 2581658 & 2217230 & 8413832 & 1696069 & 0.16208 & 28851.1 & 19874.0 & 263239 & 31611.0 & 0.119\\
	 			$f_{4}$ & -2299.87 & -2285.58 & 921.81 & 172.276 & 2.47826 & -1696.10 & -2306.78 & 4879.97 & 1489.37 & inf & -3858.67 & -3859.33 & 110.48 & 23.9797 & 0.1687 & -3842.75 & -3842.15 & 87.37 & 16.4009 & 0.1593\\
	 			$f_{5}$ & 56.7817 & 0.0 & 253.317 & 98.5212 & 1.77012 & 292.995 & 358.479 & 729.753 & 179.170 & inf & 3.28126 & 3.19112 & 4.32585 & 0.81125 & 0.17219 & 1.05707 & 1.05306 & 0.34871 & 0.04283 & 0.13114\\
	 			$f_{6}$ & -20.2607& -20.2467 & 2.9403 & 0.56734 & 1.71171 & -19.2681& -19.4156 & 7.3852 & 1.85932 & inf & -26.0518 & -26.0718 & 2.4264 & 0.45639& 0.17534 & -21.8977 & -21.958 & 2.9418 & 0.52714 & 0.24817\\
	 			$f_{7}$ & 83.8337 & 84.0244 & 15.0608 & 3.12880 & 2.98543 & 82.8599 & 78.1999 & 65.623 & 18.3324 & inf & 30.2597 & 30.4624 & 19.8864 & 3.76810 & 0.18158 & 28.2205 & 28.2178 & 19.6238 & 4.28851 & 0.17024\\
	 			$f_{8}$ & 169.674 & 171.938 & 62.452 & 13.1044 & 2.52539 & 188.489 & 172.192 & 290.391 & 84.3464 & inf & -18.2855 & -18.5622 & 36.09521 & 7.46914 & 0.17230 & 7.29205 & 7.42419 & 36.4385 & 7.76453 & 0.16940\\
	 			$f_{9}$ & 284.647 & 286.35 & 41.814 & 8.75306 & 2.85214 & 287.294 & 279.365 & 181.885 & 50.2402 & inf & 83.5881 & 82.8700 & 61.2767 & 12.1416 & 0.1745 & 46.038 & 46.1045 & 36.9832 & 8.43617 & 0.13987\\
	 			$f_{10}$ & -5893.20& -5847.27 & 2002.5 & 358.505 & 2.6768 & -2186.70 & -2266.55 & 6263.64 & 1064.90 & inf & -11536.7 & -11509.2 & 4564.43 & 831.925 & 0.17535 & -5336.97 & -5291.41 & 2605.34 & 430.420& 0.30067\\
	 			$f_{11}$ & -3511.71 & -3478.2 & 1143.42 & 224.483 & 2.45246 & -2273.60 & -2290.01 & 2855.53 & 600.087 & inf & -6697.23 & -6704.77 & 1243.58 & 243.920 & 0.16849 & -3109.77 & -3096.47 & 1404.78 & 266.862 & 0.29929\\
	 			$f_{12}$ & 2.43842 & 2.61453 & 3.40053 & 0.70495 & 1.8296 & 8.38938 & 8.48324 & 2.17456 & 0.50098 & inf & 4.07366 & 4.09426 & 2.05436 & 0.43959 & 0.17178 & 7.32333 & 7.34228 & 1.06215 & 0.19573 & 0.28271\\
	 			$f_{13}$ & -7.87700 & -7.82526 & 2.52269 & 0.45672 & 2.52861 & -6.38434 & -6.38371 & 3.04378 & 0.67772 & inf & -16.4700 & -16.4495 & 3.4316 & 0.64308 & 0.17902 & -8.44269 & -8.36709 & 2.83707 & 0.58818 & 0.25933\\
	 			$f_{14}$ & -4.39571 & -4.16666 & 4.63569 & 0.89474 & 1.82248 & -1.24342 & -1.20548 & 4.58493 & 0.77448 & inf & -10.4523 & -10.5127 & 5.1575 & 1.06563 & 0.17053 & -3.09349 & -3.05453 & 1.81532 & 0.33962 & 0.26706\\
				
	\noalign{\smallskip}\hline\noalign{\smallskip}
				Mean & $2\times10^{8}$ & $2\times10^{8}$ & $2\times10^{8}$ & $5\times10^{7}$ & 2.36362 & $1\times10^{9}$ & $1\times10^{9}$ & $3\times10^{9}$ & $9\times10^{8}$ & inf & 182307 & 156275 & 601528 & 121250 & 0.16394 & 897.179 & 261.760 & 19205.2 & 2332.36 & 0.20783 \\
	\noalign{\smallskip}\hline\noalign{\smallskip}
	\multicolumn{16}{l}{\tiny $^1$ 3.2GHz AMD Ryzen 7 1700X, 16 GB RAM}
		\end{tabular}\label{DE1_10}
	\end{table}
\end{landscape}

\pagebreak

\begin{landscape}
	\begin{table}
		\tiny
		\centering
		\caption{Computation comparison for PSO, FFA, GA, and DE/best/1/exp in 30 dimensions}
		\label{Tab1d}
		\begin{tabular}{c|ccccc|ccccc|ccccc|ccccc}
			\noalign{\smallskip}\hline\noalign{\smallskip}
			Problem & \multicolumn{5}{c}{PSO}& \multicolumn{5}{|c|}{FFA} &  \multicolumn{5}{c}{GA} & \multicolumn{5}{c}{Differential Evolution (best/1/exp)}\\  
			\noalign{\smallskip}\hline\noalign{\smallskip}
			& Avg & Median & Range & SD & T(s) & Avg & Median
			& Range & SD & T(s) & Avg & Median & Range & SD &
			T(s) & Avg & Median & Range & SD &
			T(s)\\ 
			\noalign{\smallskip}\hline\noalign{\smallskip}
			$f_{1}$ & -4747.62 & -4655.9 & 2432.24 & 368.482 & 3.72 & -2176.02 & -2271.92 & 4946.47 & 739.195 & inf & -10230 & -10224.8 & 1605.78 &  318.308 & 0.13 & -4468.39& -4477.94 & 2181.72 & 382.854 & 0.30\\
			$f_{2}$ & 35656.9 & 36421.8 & 16747.8 & 3450.71 & 3.73 & 46571.5 & 18443.9 & 103019 & 38751.8 & inf & 2794.16 & 2751.68 & 3089.31 & 712.064 & 0.12 & 281.058 & 278.273 & 552.193 & 128.777 & 0.13\\
			$f_{3}$ & $9\times10^{9}$ & $9\times10^{9}$ & $8\times10^{9}$ & $1\times10^{9}$ & 3.67 & $1\times10^{10}$ & $1\times10^{9}$ & $7\times10^{10}$ & $2\times10^{10}$ & inf & $9\times10^{7}$ & $9\times10^{7}$ & $2\times10^{8}$ & $4\times10^{7}$ & 0.18 & $5\times10^{7}$ & $3\times10^{7}$ & $6\times10^{7}$ & $7\times10^{7}$ & 0.13\\
			$f_{4}$ & -2525.22 & -2486.53 & 1538.75 & 318.241 & 3.69 & -3239.54 & -4293.12 & 7770.96 & 2158.85 & inf & -5488.18 & -5489.28 & 427.89 & 70.2765 & 0.19 & -5660.24 & -5665.19 & 169.52 & 36.0787 & 0.16\\
			$f_{5}$ & 336.197 & 341.102 & 164.004 & 31.6280 & 3.29 & 318.473 & 76.4940 & 905.997 & 289.549 & inf & 19.6339 & 19.5284 & 17.336 & 3.79079 & 0.19 & 2.73123 & 2.52172 & 4.62583 & 0.88190 & 0.15\\
			$f_{6}$ & -28.6745 & -28.6286 & 3.3432 & 0.6441 & 2.79 & -30.2043 & -30.9041 & 11.8816 & 2.43257 & inf & -36.90566 & -36.8528 & 3.4591 & 0.6512 & 0.19 & -30.9149 & -30.8490 & 3.0272 & 0.53735 & 0.29\\
			$f_{7}$ & 140.859 & 141.503 & 20.991 & 4.05389& 4.50 & 116.004 & 107.987 & 110.388 & 23.4030 & inf & 69.6765 & 69.9852 & 25.967 & 5.3395 & 0.21 & 72.5874 & 71.6857 & 41.1703 & 7.50465 & 0.22\\
			$f_{8}$ & 315.967 & 319.907 & 109.484 & 18.1027 & 3.90 & 230.343 & 175.583 & 431.179 & 117.149 & inf & 39.8534 & 39.2247 & 87.0006 & 15.1161 & 0.19 & 63.7954 & 63.3944 & 80.6115 & 16.5474 & 0.19\\
			$f_{9}$ & 470.222 & 472.849 & 72.461 & 12.2049 & 4.30 & 423.385 & 400.074 & 259.415 & 69.3402 & inf & 210.152 & 210.935 & 107.436 & 20.1423 & 0.19 & 160.564 & 158.519 & 138.235 & 25.2686 & 0.17\\
			$f_{10}$ & -7352.77 & -7303.52 & 1863.51 & 428.409 & 4.03 & -3454.39 & -3594.99 & 5231.671 & 875.328 & inf & -14635.10 & -14693.1 & 4334.9 & 929.969 & 0.19 & -6172.62 & -6075.52 & 2683.87 & 503.846 & 0.35\\
			$f_{11}$ & -4253.62 & -4238.21 & 1469.89 & 308.118 & 3.67 & -2702.36 & -2728.92 & 3188.17 & 677.954 & inf & -8675.03 & -8679.99 & 1689.55 & 407.266 & 0.18 & -3484.30 & -3438.85 & 1564.1 & 300.273 & 0.34\\
			$f_{12}$ & 4.84055 & 5.20066 & 5.33375 & 1.38615 & 2.66 & 12.7920 & 12.7003 & 2.7997 & 0.61236 & inf & 7.93813 & 7.96789 & 2.26469 & 0.48373 & 0.19 & 12.1406 & 12.1846 & 1.0327 & 0.22081 & 0.33\\
			$f_{13}$ & -10.0072 & -9.90087 & 2.21693 & 0.47841 & 3.92 & -8.61304 & -8.59052 & 3.61292 & 0.72079 & inf & -20.9753 & -20.9974 & 4.6779 & 0.85301 & 0.20 & -9.84538 & -9.81519 & 3.08913 & 0.64179 & 0.33\\
			$f_{14}$ & -4.96424 & -4.88993 & 4.53361 & 0.92952 & 2.72 & -1.93540 & -2.02921 & 4.22490 & 0.96781 & inf & -11.6296 & -11.5492 & 5.37561 & 1.07575 & 0.19 & -3.06596 & -3.01798 & 1.77323 & 0.34881 & 0.32\\
			
			\noalign{\smallskip}\hline\noalign{\smallskip}
			Mean & $6\times10^{8}$ & $6\times10^{8}$ & $5\times10^{10}$ & $1\times10^{9}$ & 3.61 & $1\times10^{9}$ & $7\times10^{7}$ & $5\times10^{9}$ & $1\times10^{9}$ & inf & $6\times10^{7}$ & $6\times10^{6}$ & $1\times10^{7}$ & $3\times10^{7}$ & 0.18 & 375662 & 228259 & $4\times10^{7}$ & 555485 & 0.24 \\
			\noalign{\smallskip}\hline\noalign{\smallskip}
			\multicolumn{16}{l}{\tiny $^1$ 3.2GHz AMD Ryzen 7 1700X, 16 GB RAM}
		\end{tabular}\label{DE1_20}
	\end{table}
\end{landscape}

% DE1



\end{document}